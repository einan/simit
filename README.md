# SimiT: A Text Similarity Method Using Lexicon and Dependency Representations

Semantic textual similarity methods are becoming increasingly crucial in text mining research areas such as text retrieval and summarization. Existing methods of text similarity have often been computed by their shallow or syntactic representation rather than considering their semantic content and meanings. This paper focuses mainly on computing the similarity between sentences without a supervised learning approach, only considering their word-level coherence which is calculated by a hybrid method of dependency parser and lexicon embeddings. Hence, we concentrate on structural similarity between text pairs by regarding their dependency parser embeddings. Our hybrid method also pays attention to the semantic information of words implied in the sentences. In the evaluation, we compare our method with the state-of-the-art semantic similarity measures in a well-known dataset. Our method outperforms most of the studies in the literature and the overall performance achieves better results when combining the similarity scores of both embedding models.

## If you want to use WeDGeM in your studies, please cite the following paper:

```
@article{inan2020simit,
  title={Simit: A text similarity method using lexicon and dependency representations},
  author={Inan, Emrah},
  journal={New Generation Computing},
  volume={38},
  number={3},
  pages={509--530},
  year={2020},
  publisher={Springer}
}
```
